{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8912c75f-cee6-4b4c-8003-01af814b1c65",
   "metadata": {},
   "source": [
    "# Example 09: PyTorch-Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6ec90-3f4d-45e7-9f8b-fdb6a9504bef",
   "metadata": {},
   "source": [
    "## äº‹å‰æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf69bae-e78c-4ee6-b5d4-b9d170535544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPUãŒä½¿ãˆã‚‹ã‹ç¢ºèªã—ã¦ãƒ‡ãƒã‚¤ã‚¹ã‚’è¨­å®š\n",
    "# NOTE: `x = x.to(device) ` ã¨ã™ã‚‹ã“ã¨ã§å¯¾è±¡ã®ãƒ‡ãƒã‚¤ã‚¹ã«åˆ‡ã‚Šæ›¿ãˆå¯èƒ½\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14db7216-d9a3-4d78-8084-83e7defcc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/north_redwing/items/1e153139125d37829d2d\n",
    "from typing import Callable\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def fixing_seed(seed: int=42) -> tuple[torch.Generator, Callable]:\n",
    "    # NOTE: æˆ»ã‚Šå€¤ã¯DataLoaderã®ã‚·ãƒ¼ãƒ‰å›ºå®šã«ä½¿ç”¨ã™ã‚‹ã€‚ã€€(ex) loader = DataLoader(..., worker_init_fn=seed_worker, generator=generator)\n",
    "    #       ã¾ãŸã€plã®Trainer(deterministic=True)ã¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚\n",
    "    # Python ã®ã‚·ãƒ¼ãƒ‰å›ºå®š\n",
    "    random.seed(seed)\n",
    "    # Numpy ã®ã‚·ãƒ¼ãƒ‰å›ºå®š\n",
    "    np.random.seed(seed)\n",
    "    # PyTorch ã®ã‚·ãƒ¼ãƒ‰å›ºå®š\n",
    "    torch.manual_seed(seed)\n",
    "    # CUDA ã®å†ç¾æ€§ç¢ºä¿ã®è¨­å®š\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # PyTorch Lightning ã®ã‚·ãƒ¼ãƒ‰å›ºå®š\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # DataLoader å„ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨\n",
    "    # --------------------------------------------------\n",
    "    # DataLoader å„ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ã®åˆæœŸåŒ–é–¢æ•°\n",
    "    def seed_worker(worker_id: int) -> None:\n",
    "        # å„ worker ã§ Python / NumPy ã‚‚å›ºå®š\n",
    "        wseed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(wseed)\n",
    "        random.seed(wseed)\n",
    "\n",
    "    # DataLoader ã®ä¹±æ•°æº\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(seed)\n",
    "\n",
    "    return generator, seed_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062fb00b-d8db-4cfc-aae1-2a490ee89fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "generator, seed_worker_fn = fixing_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d77e57-3c12-46a1-ae14-e4e06a518f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b264-322b-4a78-a1a2-c4268bda63d7",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27c5af6-f5c1-4343-ad8a-33b38a77d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torchinfo\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056ccfe-7dab-4f41-af4d-ce913e540dfa",
   "metadata": {},
   "source": [
    "### è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š(optuna)\n",
    "\n",
    "ä»Šå›žã¯ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡ã¨ã™ã‚‹ã€‚\n",
    "\n",
    "- æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n",
    "- æ´»æ€§åŒ–é–¢æ•°\n",
    "- ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆçŽ‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3bc8c-6839-457e-9298-93dedad3d9f1",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae79c3c3-503d-464b-b26c-ac0b174bb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adam_optimizer(trial: optuna.trial.Trial, model: nn.Module) -> optim.Optimizer:\n",
    "    lr = trial.suggest_float('adam_lr', 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float('adam_weight_decay', 1e-10, 1e-3)\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "def get_momentum_sgd_optimizer(trial: optuna.trial.Trial, model: nn.Module) -> optim.Optimizer:\n",
    "    lr = trial.suggest_float('momentum_sgd_lr', 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float('momentum_sgd_weight_decay', 1e-10, 1e-3, log=True)\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=0.9,\n",
    "                          weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "def get_rms_prob_optimizer(trial: optuna.trial.Trial, model: nn.Module) -> optim.Optimizer:\n",
    "    lr = trial.suggest_float('rms_prob_lr', 1e-5, 1e-1, log=True)\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1a038c-e9b5-4cd3-b247-44bb9f33beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(trial: optuna.trial.Trial, model: nn.Module) -> optim.Optimizer:\n",
    "    optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n",
    "    \n",
    "    if optimizer_name == 'Adam': \n",
    "        optimizer = get_adam_optimizer(trial, model)\n",
    "    elif optimizer_name == 'MomentumSGD':\n",
    "        optimizer = get_momentum_sgd_optimizer(trial, model)\n",
    "    else:\n",
    "        optimizer = get_rms_prob_optimizer(trial, model)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15489de1-872e-42bd-9c70-ca4500e49cde",
   "metadata": {},
   "source": [
    "#### æ´»æ€§åŒ–é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3639a3af-79d4-463a-83c2-fff27b77e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(trial: optuna.trial.Trial) -> nn.Module:\n",
    "    activation_names = ['ReLU', 'Tanh']\n",
    "    activation_name = trial.suggest_categorical('activation', activation_names)\n",
    "    \n",
    "    if activation_name == 'ReLU':\n",
    "        activation = nn.ReLU()\n",
    "    else:\n",
    "        activation = nn.Tanh()\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39245e-d29f-4811-a37e-991274e3fc09",
   "metadata": {},
   "source": [
    "#### ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b5a7c4-b94e-49ad-b237-0b3944b743d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparam(trial: optuna.trial.Trial) -> dict[str, Any]:\n",
    "    return {\n",
    "        'dropout_prob': trial.suggest_float('dropout_prob', 0.2, 0.8, step=0.1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407675a5-7230-41d8-b265-cc7c1f52d820",
   "metadata": {},
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730bc4e0-63fd-413f-95f4-38faff272451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes: int,\n",
    "                       dropout_prob: float = 0.5,\n",
    "                       activation_func: nn.Module = nn.ReLU()):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5)         # å…¥åŠ›ãƒãƒ£ãƒãƒ«ã€å‡ºåŠ›ãƒãƒ£ãƒãƒ«ã€ãƒ•ã‚£ãƒ«ã‚¿æ•°\n",
    "        self.active = activation_func\n",
    "        self.pool = nn.MaxPool2d(2, 2)          # é ˜åŸŸã®ã‚µã‚¤ã‚ºã€é ˜åŸŸã®é–“éš”\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 256)\n",
    "        self.dropout = nn.Dropout(dropout_prob)          # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆçŽ‡\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.active(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.active(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.active(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7443775-a776-41d9-a0d6-553aa027625a",
   "metadata": {},
   "source": [
    "### PyTorch Lightning ãƒ¢ãƒ‡ãƒ«ç”¨æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c706ec-48fb-46c3-8e55-2dc2faa356d0",
   "metadata": {},
   "source": [
    "#### ãƒ­ã‚¬ãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f95c0db3-7df9-4b2b-b134-c662668b62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictLogger(pl.loggers.Logger):\n",
    "    \"\"\"PyTorch Lightning `dict` logger.\"\"\"\n",
    " \n",
    "    def __init__(self, version):\n",
    "        super(DictLogger, self).__init__()\n",
    "        self.metrics = []\n",
    "        self._version = version\n",
    " \n",
    "    def log_metrics(self, metric, step_num=None):\n",
    "        self.metrics.append(metric)\n",
    " \n",
    "    @property\n",
    "    def version(self):\n",
    "        return self._version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895e47c-c39e-4ce3-b009-3dd9aa8f4d78",
   "metadata": {},
   "source": [
    "#### ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bf30e99-38fc-4de6-9bab-e821f4ded82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, root_dir: str=\"../cache/data\", batch_size: int=128, valid_size: float=0.2, num_workers: int=0):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_size = valid_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.RandomAffine((-30, 30), scale=(0.8, 1.2)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.0, 0.0, 0.0), (1.0, 1.0, 1.0)),\n",
    "        ])\n",
    "        self.valid_transform = transforms.Compose([\n",
    "            transforms.RandomAffine((-30, 30), scale=(0.8, 1.2)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.0, 0.0, 0.0), (1.0, 1.0, 1.0)),\n",
    "        ])\n",
    "        self.test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.0, 0.0, 0.0), (1.0, 1.0, 1.0)),\n",
    "        ])\n",
    "\n",
    "    def _prepare_train_valid_index(self, data_length: int, valid_size: float = 0.2) -> tuple[SubsetRandomSampler, SubsetRandomSampler]:\n",
    "        indices = list(range(data_length))\n",
    "        split = int(np.floor(valid_size * data_length))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        train_idx = indices[split:]\n",
    "        valid_idx = indices[:split]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        validation_sampler = SubsetRandomSampler(valid_idx)\n",
    "        return (train_sampler, validation_sampler) \n",
    "    \n",
    "    def prepare_data(self) -> None:\n",
    "        train_dataset = CIFAR10(self.root_dir, train=True, download=True)\n",
    "        CIFAR10(self.root_dir, train=False, download=True)\n",
    "        self.train_sampler, self.valid_sampler = self._prepare_train_valid_index(len(train_dataset), self.valid_size)\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = CIFAR10(self.root_dir, train=True, transform=self.train_transform)\n",
    "            self.valid_dataset = CIFAR10(self.root_dir, train=True, transform=self.valid_transform)\n",
    "        elif stage == \"test\":\n",
    "            self.test_dataset = CIFAR10(self.root_dir, train=False, transform=self.test_transform)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, sampler=self.train_sampler)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, sampler=self.valid_sampler)\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, worker_init_fn=seed_worker_fn, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc90a283-7072-4eb9-8253-def89a84a37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "///// fit /////\n",
      "{Train dataloader: size=50000}\n",
      "{Validation dataloader: size=50000}\n",
      "{Test dataloader: None}\n",
      "{Predict dataloader: None}\n",
      "\n",
      "///// test /////\n",
      "{Train dataloader: size=50000}\n",
      "{Validation dataloader: size=50000}\n",
      "{Test dataloader: size=10000}\n",
      "{Predict dataloader: None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_datamodule():\n",
    "    dm = CIFAR10DataModule()\n",
    "    dm.prepare_data()\n",
    "    for stage in (\"fit\", \"test\"):\n",
    "        dm.setup(stage)\n",
    "        print(f\"///// {stage} /////\")\n",
    "        print(dm)\n",
    "        print()\n",
    "\n",
    "check_datamodule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6c87d-6498-4f17-9d92-ab5adc40470a",
   "metadata": {},
   "source": [
    "#### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07058f68-6454-4f41-a712-baecb8971430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = correct / output.size(0)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class LightningNet(pl.LightningModule):\n",
    " \n",
    "    def __init__(self, trial: optuna.trial.Trial, n_class: int, batch_size: int = 128):\n",
    "        super(LightningNet, self).__init__()\n",
    "        self.trial = trial\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        hyperparam = get_hyperparam(self.trial)\n",
    "        activation = get_activation(self.trial)        \n",
    "        self.model = Net(n_class, hyperparam['dropout_prob'], activation)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(data)\n",
    " \n",
    "    def training_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, torch.Tensor]:\n",
    "        data, target = batch\n",
    "        output = self.forward(data)\n",
    "        loss = criterion(output, target)\n",
    "        accuracy = calc_accuracy(output, target)\n",
    "        return {\n",
    "            'train_loss': loss,\n",
    "            'train_accuracy': accuracy\n",
    "        }\n",
    " \n",
    "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, torch.Tensor]:\n",
    "        data, target = batch\n",
    "        output = self.forward(data)\n",
    "        loss = criterion(output, target) \n",
    "        accuracy = calc_accuracy(output, target)\n",
    "        return {\n",
    "            'valid_loss': loss,\n",
    "            'valid_accuracy': accuracy\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    def validation_end(self, outputs) -> dict[str, Any]:\n",
    "        accuracy = sum(x['valid_accuracy'] for x in outputs) / len(outputs)\n",
    "        # Pass the accuracy to the `DictLogger` via the `'log'` key.\n",
    "        return {'log': {'accuracy': accuracy}}\n",
    "    \"\"\"\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Generate the optimizers.\n",
    "        return get_optimizer(self.trial, self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048a57f-7b0f-464f-ba80-61b1b3cd9028",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79da6d03-f719-4553-99f0-3e1cb0297518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "#data_module = CIFAR10DataModule()\n",
    "#data_module.prepare_data()\n",
    "#data_module.setup(stage=\"fit\")\n",
    "\n",
    "#logger = DictLogger(trial.number)\n",
    "\n",
    "#trainer = pl.Trainer(\n",
    "#    gpus=1,\n",
    "#    max_epochs=30,\n",
    "#    deterministic=True)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    deterministic=True)\n",
    "\n",
    "#model = LightningNet(num_classes=dm.num_classes, width=dm.width, vocab=dm.vocab)\n",
    "#trainer.fit(model, data_module)\n",
    "\n",
    "#data_module.setup(stage=\"test\")\n",
    "#trainer.test(datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c561af5-052d-441f-802b-9b4fab517e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec97eae5-3f13-4097-8a44-9f642469b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningNet_DUMMY(pl.LightningModule):\n",
    " \n",
    "    def __init__(self, n_class: int = 10, batch_size: int = 128):\n",
    "        super(LightningNet_DUMMY, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.model = Net(n_class)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(data)\n",
    " \n",
    "    def training_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, torch.Tensor]:\n",
    "        data, target = batch\n",
    "        output = self.forward(data)\n",
    "        loss = self.criterion(output, target)\n",
    "        accuracy = calc_accuracy(output, target)\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    " \n",
    "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, torch.Tensor]:\n",
    "        data, target = batch\n",
    "        output = self.forward(data)\n",
    "        loss = self.criterion(output, target) \n",
    "        accuracy = calc_accuracy(output, target)\n",
    "        return {\n",
    "            'valid_loss': loss,\n",
    "            'valid_accuracy': accuracy\n",
    "        }\n",
    "\n",
    "    # TODO: ãƒãƒƒãƒã”ã¨ã«å¿…è¦ï¼Ÿ\n",
    "    def test_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, torch.Tensor]:\n",
    "        data, target = batch\n",
    "        output = self.forward(data)\n",
    "        loss = self.criterion(output, target) \n",
    "        accuracy = calc_accuracy(output, target)\n",
    "        return {\n",
    "            'test_loss': loss,\n",
    "            'test_accuracy': accuracy\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    def validation_end(self, outputs) -> dict[str, Any]:\n",
    "        accuracy = sum(x['valid_accuracy'] for x in outputs) / len(outputs)\n",
    "        # Pass the accuracy to the `DictLogger` via the `'log'` key.\n",
    "        return {'log': {'accuracy': accuracy}}\n",
    "    \"\"\"\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Generate the optimizers.\n",
    "        return optim.Adam(self.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49186bec-fd16-469d-979b-6b6823337c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | Net              | 109 K  | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.436     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb7e52e9dd141489131974bfdb287be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3e5a3b790f497fa55939038caf2af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e141bf2047864e619d8bb64627db966e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9287df4c244be388ed9cc0b6d25870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6614577def0e4634b9c7835b0c0f173b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99b6330a0e34e3dbe2a63277b4cb550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d3784ed68f4b018bd164350147d7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af9623902844e4d84c1394ea6419de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab476ecaf434750a35ec518e9b2bd19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa413cc678504b778c3ff232be275ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4a7195ec6449bd8c4bcc5def34837f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d267ccf1a6b4fe581307c7e68aece3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ca2ba7a24a4d9c97217662b3de6f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a07e120551f442a9956ac3f454e2e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c1175f7f70481cb6df24f589f5a0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6cafd57e8e4d359d925ad2514087ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f91adbbe168412f9050d6d42579d96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851b44eb787f4600a77e8757d8ac17e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fb7ea7dab74ff3adab6bb80cc7019a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd63dbfd4c5449608d098ad7eb1b33dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24da50b1a95747f28b22ec9db469e5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b972776c9054245b97dcab90c6dc44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917f96d6063e487c97cb21795bf33c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667b5500c74439489bbfe593736b201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9968a01f562a42378b27136222f04d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f36d8e27464f61a76b2deb99b957dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed494f484d6a46f6847475435dd07c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbc41f4012c49df9bc97d23cc48c06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e86ad03d144c57b1fba7f9ef2114db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2008405e85b24666b5035d3e508676d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220cb2cd1158401cb4cd9fd7af8ee600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6359d7de7652486abff88e9eccb2b2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/opt/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:149: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /example-pytorch/examples/lightning_logs/version_4/checkpoints/epoch=29-step=9390.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /example-pytorch/examples/lightning_logs/version_4/checkpoints/epoch=29-step=9390.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665238f646ee4085bcdc0d8a76bbaa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:149: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /example-pytorch/examples/lightning_logs/version_4/checkpoints/epoch=29-step=9390.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /example-pytorch/examples/lightning_logs/version_4/checkpoints/epoch=29-step=9390.ckpt\n",
      "/opt/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:484: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d345c0c46724d3698ad8b1af661b0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = CIFAR10DataModule(num_workers=NUM_WORKERS)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"fit\")\n",
    "\n",
    "model = LightningNet_DUMMY()\n",
    "trainer.fit(model, dm)\n",
    "trainer.validate(datamodule=dm)\n",
    "\n",
    "dm.setup(stage=\"test\")\n",
    "trainer.test(datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c40686-b020-4feb-b57d-4c82d90bf738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
